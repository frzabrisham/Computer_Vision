{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyGtmmrsK1cX"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "from cv2 import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "folders_name = ['Inside_City', 'Store', 'Mountain', 'Tall_Building', 'Open_Country', 'Highway', 'Kitchen', 'Coast',\n",
    "                'Office', 'Bedroom', 'Suburb', 'Livingroom', 'Street', 'Industrial', 'Forest']\n",
    "\n",
    "sift = SIFT_create()\n",
    "descriptors = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUV0__N5N_64"
   },
   "source": [
    "در این قسمت سیفت و ایمپورت‌ها هستند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIsSAiG2N_iX"
   },
   "outputs": [],
   "source": [
    "def find_feature(path, type_of_data):\n",
    "    im_list = listdir(path)\n",
    "    D = list()\n",
    "    for file in im_list:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            im = imread(path + file)\n",
    "            _, des = sift.detectAndCompute(im, None)\n",
    "            if type_of_data == 'Train':\n",
    "                for d in des:\n",
    "                    descriptors.append(d)\n",
    "\n",
    "            D.append(des)\n",
    "    return D\n",
    "\n",
    "\n",
    "def init_desc(type_of_data):\n",
    "    folder = 'Data/' + type_of_data + '/'\n",
    "    desc = list()\n",
    "    for f in folders_name:\n",
    "        desc.append(find_feature(folder + f + '/', type_of_data))\n",
    "    return desc\n",
    "\n",
    "\n",
    "desc_train = init_desc('Train')\n",
    "desc_test = init_desc('Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuRd_2UoPhzv"
   },
   "source": [
    "در این قسمت از کد ابتدا دیسکریپتورهای هر عکس را حساب کردم و دیسکریپتورهای داده‌های آموزش را در یک لیست دیسکریپتور ریختم. هم‌چنین دیسکریپتورهای آموزش و تست را به صورت جداگانه در لیست‌هایی قرار دادم که در قسمت بعد از آن استفاده کنم\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYTMW-COP_45"
   },
   "outputs": [],
   "source": [
    "\n",
    "n_cluster = [50, 80, 100]\n",
    "\n",
    "Train_X, Train_Y = list(), list()\n",
    "Test_X, Test_Y, True_Y = list(), list(), list()\n",
    "max_percent = 0\n",
    "for n in n_cluster:\n",
    "    k_means = KMeans(n_clusters=n, random_state=0).fit(descriptors)\n",
    "\n",
    "    train_X, train_Y = list(), list()\n",
    "    test_X, test_Y, true_Y = list(), list(), list()\n",
    "\n",
    "\n",
    "    def training(index):\n",
    "        for des in desc_train[index]:\n",
    "            h = np.zeros(n)\n",
    "            for d in des:\n",
    "                p = k_means.predict([d])\n",
    "                h[p] += 1\n",
    "            train_X.append(h.reshape(-1))\n",
    "            train_Y.append(index)\n",
    "\n",
    "\n",
    "    for i in range(len(folders_name)):\n",
    "        training(i)\n",
    "\n",
    "\n",
    "    def test(index):\n",
    "        for des in desc_test[index]:\n",
    "            h = np.zeros(n)\n",
    "            for d in des:\n",
    "                p = k_means.predict([d])\n",
    "                h[p] += 1\n",
    "            test_X.append(h.reshape(-1))\n",
    "            true_Y.append(index)\n",
    "\n",
    "\n",
    "    for i in range(len(folders_name)):\n",
    "        test(i)\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    clf.fit(train_X, train_Y)\n",
    "    test_Y = clf.predict(test_X)\n",
    "\n",
    "    C = confusion_matrix(true_Y, test_Y)\n",
    "    correct = 0\n",
    "    for i in range(len(folders_name)):\n",
    "        correct += C[i, i]\n",
    "    print('n_cluster: ' + str(n))\n",
    "    per = correct / len(folders_name)\n",
    "    print(per)\n",
    "    if per > max_percent:\n",
    "        max_percent = per\n",
    "        df_cm = pd.DataFrame(C, folders_name, folders_name)\n",
    "        sn.set(font_scale=0.4)\n",
    "        sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "        plt.savefig('res09.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHiHyZovQHxn"
   },
   "source": [
    "در این بخش برای یافتن مقدار بهینه و بیشتر درصد برای جواب تعداد کلاسترهای متفاوت را امتحان کردم. ابتدا 3 عدد 50 و 80 و 100 را گرفتم و تعداد کلاسترها را روی این اعداد ست کردم و یک فور کلی زدم. سپس در تابع ترینینگ اندیس که نشان‌دهنده‌ی نوع داده(عکس) است را گرفتم و با استفاده از پردیکت $kmeans$ \n",
    "هموگرافی هر عکس را می‌سازم. این تابع به این صورت عمل می‌کند که برای هر عکس دیسکریپتورها را می‌گیرد و با توجه به کلاسترها می‌گوید در کدام کلاستر می‌افتد. سپس بردار $h$\n",
    "را در آن نقطه یک واحد افزایش می‌دهیم.\n",
    "حال این بردارها را به عنوان فیچر وکتور هر عکس به ماتریس آموزش می‌دهیم و برای $Y$ آن نیز\n",
    "اندیس نوع داده را به آن نسبت می‌دهیم، روی همه‌ی نوع داده‌ها فور می‌زنیم و فیچروکتور همه عکس‌های آموزش را محاسبه می‌کنیم. \n",
    "در قسمت بعد تابع تست اینگونه است که مانند تابع آموزش عمل می‌کند و فیچر وکتور هر عکس تست را محاسبه می‌کند و به ماتریس $test\\_X$ اضافه می‌کند و هم‌چنین مقدار واقعی را به ماتریس \n",
    "$true\\_Y$ \n",
    "اضافه می‌کند.\n",
    "این ماتریس را بعدا با ماتریسی که پردیکت می‌شود مقایسه می‌کنیم و درصد درستی جواب حدس زده شده را محاسبه می‌کنیم.\n",
    "در این قسمت\n",
    "\n",
    "```\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    clf.fit(train_X, train_Y)\n",
    "    test_Y = clf.predict(test_X)\n",
    "```\n",
    "\n",
    "با استفاده از روش $SVM$\n",
    "داده‌های آموزش را فیت می‌کنیم و داده‌های تست را پردیکت می‌کنیم.\n",
    "مقادیر حدس زده شده برای لیبل داده‌های تست را می‌گیریم .\n",
    "\n",
    "سپس با استفاده از تابع\n",
    "\n",
    "\n",
    "> confusion_matrix()\n",
    "\n",
    "ماتریس کانفیوژن را محاسبه کرده و هم‌چنین درصد ماکسیمم را نگه می‌دارم که نمایش ماتریس کانفیوژن پایانی برای ماکسیمم باشد.\n",
    "\n",
    "هم‌چنین نتایج بدست آمده برای \n",
    "$n$های \n",
    "(مقادیر کلاستر) متفاوت به شرح زیر است:\n",
    "\n",
    "```\n",
    "n_cluster: 50\n",
    "52.733333333333334%\n",
    "\n",
    "n_cluster: 80\n",
    "53.4%\n",
    "\n",
    "n_cluster: 100\n",
    "54.666666666666664%\n",
    "\n",
    "```\n",
    "\n",
    "که بهترین نتیجه برای مقدار \n",
    "$n=100$\n",
    "است.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "q4p3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
